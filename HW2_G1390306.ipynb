{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91db6757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from imblearn.over_sampling import SMOTE,RandomOverSampler\n",
    "from imblearn.combine import SMOTEENN,SMOTETomek\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad317c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Training dataset\n",
    "with open(\"/Users/sanjanagovindu/Downloads/DMAsst2/train_file.csv\", \"r\") as trainData:\n",
    "    train = trainData.readlines()\n",
    "\n",
    "#Loading Test dataset\n",
    "with open(\"/Users/sanjanagovindu/Downloads/DMAsst2/test_file.csv\", \"r\") as testData:\n",
    "    test = testData.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f07c34cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = []\n",
    "train_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f28fd30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the given training and test data into matrix\n",
    "def convert_matrix_split(data):\n",
    "    feat_range = 100000\n",
    "    sp_matrix = pd.DataFrame(columns=range(feat_range))\n",
    "    l = len(data)\n",
    "    for i in range(l):\n",
    "        xarr = [0 for j in range(feat_range)]\n",
    "        for k in np.fromstring(data[i], dtype=int, sep=' '):\n",
    "            xarr[k-1] = 1\n",
    "        sp_matrix.loc[i] = xarr\n",
    "    return sp_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0dc6c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train:\n",
    "    train_label.append(data[0])\n",
    "    \n",
    "    #Remove new line and activity label - 0/1 from each row\n",
    "    data = data.replace(\"\\n\", \"\")\n",
    "    data = data.replace(\"0\\t\", \"\")\n",
    "    data = data.replace(\"1\\t\", \"\")\n",
    "    train_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70f322c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = convert_matrix_split(train_list)\n",
    "test_data = convert_matrix_split(test)\n",
    "y_train = np.asarray(train_label) #convert the input train_label into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efcb7c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceDimentionality(train_data, test_data):\n",
    "    #Applying PCA - Principal Component Analysis to reduce dimentionality\n",
    "    #red_dim = PCA(n_components=1000)\n",
    "    \n",
    "    #Applying SVD -  Singular Value Decomposition to reduce dimentionality\n",
    "    #svd = TruncatedSVD(n_components=1000)\n",
    "    red_dim = TruncatedSVD(n_components=500, random_state=42)\n",
    "\n",
    "    train_vector = red_dim.fit_transform(train_data)\n",
    "    test_vector = red_dim.transform(test_data)\n",
    "    return train_vector, test_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f91d4f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performClassification(train_data, test_data, y_train):\n",
    "    pred_values = []\n",
    "\n",
    "    #Naive Bayes - Bernoulli's Classification\n",
    "    print(\"Performing - Naive Bayes - Bernoulli's Classification\")\n",
    "    bnb = BernoulliNB().fit(train_data, y_train)\n",
    "    #bnb.fit(train_data, y_train)\n",
    "    pred_values = bnb.predict(test_data)\n",
    "    \n",
    "    #Naive Bayes - Guassian Classification\n",
    "    #print(\"Naive Bayes - Guassian Classification\")\n",
    "    #gnb = GaussianNB().fit(train_data, y_train)\n",
    "    #pred_values = gnb.predict(test_data)\n",
    "    \n",
    "    #Decision Tree Classification\n",
    "    #print(\"Decision Tree Classification\")\n",
    "    #dtree = DecisionTreeClassifier().fit(train_data, y_train)\n",
    "    #pred_values = dtree.predict(test_data)\n",
    "    \n",
    "    #Neural Networks - Multilayer Perceptron Classification \n",
    "    #print(\"Multilayer Perceptron Classification\")\n",
    "    #m_percept = MLPClassifier(max_iter=300, activation='relu', solver='adam', hidden_layer_sizes=(5,5,5))\n",
    "    #m_percept.fit(train_data, y_train)\n",
    "    #pred_values = m_percept.predict(test_data)\n",
    "\n",
    "    return pred_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78ee3f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.7 of training data and 0.3 of the test data\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=r) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf2675e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimentionality Reduction using SVD technique\n",
    "train_vector, test_vector = reduceDimentionality(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c9939",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dealing with imbalanced data using SMOTE, SMOTEENN, SMOTE Tomek and Random Over Sampler\n",
    "# smote = SMOTE(random_state = 42)\n",
    "# train_vector, y_train = smote.fit_resample(train_vector, y_train)\n",
    "\n",
    "# smoteTomek = SMOTETomek(random_state=42)\n",
    "# train_vector, y_train = smoteTomek.fit_resample(train_vector, y_train)\n",
    "\n",
    "# smoteenn = SMOTEENN(random_state=42)\n",
    "# train_vector, y_train = smoteenn.fit_resample(train_vector, y_train)\n",
    "\n",
    "# randomOverSampler = RandomOverSampler(random_state=42)\n",
    "# train_vector, y_train =ros.fit_resample(train_vector, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4df14a88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing - Naive Bayes - Bernoulli's Classification\n"
     ]
    }
   ],
   "source": [
    "#Classification method application for the training and test matrices after dimentionality reduction\n",
    "predictions = performClassification(train_vector, test_vector, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d1c617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output file with predictions for F1-score calculation\n",
    "out = open('/Users/sanjanagovindu/Downloads/DMAsst2/output.csv', 'w')\n",
    "\n",
    "out.writelines( \"%s\\n\" % x for x in predictions)\n",
    "\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df51a0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions)) #No of rows in output file - 350 rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
